# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HiJGSFcDuslR2K9ghKtit7cf9hRE95VH
"""

!pip install mediapipe

drive.mount('/content/drive')

import os
import cv2
import json
import numpy as np, os
import mediapipe as mp
import glob
from google.colab import drive
import unicodedata

def normalize_fname(name: str) -> str:
    """
    파일명 normali
    - 앞뒤 공백 제거
    - basename만 사용
    - 유니코드 정규화
    - 소문자 통일
    """
    name = name.strip()
    name = os.path.basename(name)
    name = unicodedata.normalize("NFC", name)
    name = name.lower()
    return name

# 원본 JSON 메타데이터 파일
METADATA_DIR = r"/content/drive/MyDrive/label"

# 샘플링 이미지
BASE_IMAGE_DIR = r"/content/drive/MyDrive/original_train_image_1k"

# 메쉬 데이터(.npy)
OUTPUT_DIR = r"/content/drive/My Drive/preprocessing_mesh_data"

EMOTION_CATEGORIES = [
    '슬픔', '기쁨', '분노', '불안', '당황', '상처', '중립'
]
PADDING_RATIO = 0.3

print("모든 원본 JSON 메타데이터를 로드 중입니다...")
metadata_map = {}

annot_A_count = 0
annot_B_count = 0
annot_C_count = 0

json_files = glob.glob(os.path.join(METADATA_DIR, '*.json'))

if not json_files:
    print(f"[오류] {METADATA_DIR}에서 JSON 파일 없음")
    raise FileNotFoundError("경로 확인 필요")
else:
    print(f"총 {len(json_files)}개의 JSON 파일")
    print(f"찾은 파일: {json_files}")

for json_file in json_files:
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if not data:
            print(f"'{json_file}' 파일이 없음")
            continue

        file_added_count = 0

        for item in data:
            if 'filename' not in item:
                continue

            # filename 정규화
            key_name = normalize_fname(item['filename'])

            if 'annot_A' in item and 'boxes' in item['annot_A']:
                if key_name not in metadata_map:
                    metadata_map[key_name] = item['annot_A']['boxes']
                    annot_A_count += 1
                    file_added_count += 1

            elif 'annot_B' in item and 'boxes' in item['annot_B']:
                if key_name not in metadata_map:
                    metadata_map[key_name] = item['annot_B']['boxes']
                    annot_B_count += 1
                    file_added_count += 1

            elif 'annot_C' in item and 'boxes' in item['annot_C']:
                if key_name not in metadata_map:
                    metadata_map[key_name] = item['annot_C']['boxes']
                    annot_C_count += 1
                    file_added_count += 1

        print(f"  -> '{os.path.basename(json_file)}' 로드. {file_added_count}개 항목 추가.")
        print(f"     (현재 metadata_map 크기: {len(metadata_map)}개)")

    except Exception as e:
        print(f"{json_file} 로드 중 오류 발생: {e}")

print(f"총 {len(metadata_map)}개의 파일 메타데이터 로드 완료.")

# MediaPipe Face Mesh 초기화
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=True,     # 이미지 파일 처리
    max_num_faces=1,            # 얼굴 1개만 탐지
    refine_landmarks=True,      # 478개 랜드마크
    min_detection_confidence=0.5
)
print("MediaPipe Face Mesh 모델 초기화 완료.")

os.makedirs(OUTPUT_DIR, exist_ok=True)
label_map = {emotion: i for i, emotion in enumerate(EMOTION_CATEGORIES)}

for emotion in EMOTION_CATEGORIES:
    emotion_label = label_map[emotion]
    img_dir = os.path.join(BASE_IMAGE_DIR, emotion)

    if not os.path.isdir(img_dir):
        print(f"'{img_dir}' 폴더를 찾을 수 없음")
        continue

    emotion_mesh_data = []
    emotion_labels = []
    processed_count = 0

    print(f"\n--- '{emotion}' (라벨: {emotion_label}) 폴더 처리 시작 ---")

    # 이미지 파일 목록
    image_files = os.listdir(img_dir)
    total_files = len(image_files)

    for i, img_filename in enumerate(image_files):
        if not img_filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue

        # 파일명 정규화
        key_name = normalize_fname(img_filename)

        boxes = metadata_map[key_name]
        img_path = os.path.join(img_dir, img_filename)

        img = cv2.imread(img_path)
        if img is None:
            print(f"  [경고] {img_filename} 파일을 읽을 수 없습니다.")
            continue

        img_h, img_w, _ = img.shape

        # 5) Loose Crop 계산
        minX, minY = boxes['minX'], boxes['minY']
        maxX, maxY = boxes['maxX'], boxes['maxY']

        padding_w = (maxX - minX) * PADDING_RATIO
        padding_h = (maxY - minY) * PADDING_RATIO

        crop_minX = int(max(0, minX - padding_w))
        crop_minY = int(max(0, minY - padding_h))
        crop_maxX = int(min(img_w, maxX + padding_w))
        crop_maxY = int(min(img_h, maxY + padding_h))

        cropped_img = img[crop_minY:crop_maxY, crop_minX:crop_maxX]

        if cropped_img.size == 0:
            print(f"  {img_filename} 크롭 사이즈가 0")
            continue

        # MediaPipe Face Mesh
        results = face_mesh.process(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0].landmark

            mesh_coords = []
            for lm in landmarks:
                mesh_coords.append([lm.x, lm.y, lm.z])

            emotion_mesh_data.append(mesh_coords)
            emotion_labels.append(emotion_label)
            processed_count += 1

        if (i + 1) % 500 == 0:
            print(f"  '{emotion}' 폴더 {i+1} / {total_files} 처리 완료...")

    if emotion_mesh_data:
        meshes_np = np.array(emotion_mesh_data)
        labels_np = np.array(emotion_labels)

        output_mesh_path = os.path.join(OUTPUT_DIR, f"meshes_{emotion}.npy")
        output_label_path = os.path.join(OUTPUT_DIR, f"labels_{emotion}.npy")

        np.save(output_mesh_path, meshes_np)
        np.save(output_label_path, labels_np)

        print(f"✅ '{emotion}' 처리 완료!")
        print(f"   -> {output_mesh_path}")
        print(f"   -> {output_label_path}")
    else:
        print(f"  '{emotion}' 폴더에서 처리할 수 있는 이미지를 찾지 못했습니다.")

for emotion in EMOTION_CATEGORIES:
    mesh_path = os.path.join(OUTPUT_DIR, f"meshes_{emotion}.npy")
    label_path = os.path.join(OUTPUT_DIR, f"labels_{emotion}.npy")
    if os.path.exists(mesh_path) and os.path.exists(label_path):
        meshes = np.load(mesh_path)
        labels = np.load(label_path)
        print(f"{emotion}: meshes={meshes.shape}, labels={labels.shape}, unique_labels={set(labels.tolist())}")
    else:
        print(f"{emotion}: 파일 없음")

